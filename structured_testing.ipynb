{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ce7e0f",
   "metadata": {},
   "source": [
    "### Prepare the code and setup database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b09d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_neo4j import Neo4jVector\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from utils.pdf_utils import extract_pdf_text_by_page, chunk_pages\n",
    "from langchain_core.messages import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05626115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and read data\n",
    "data_path = \"data_json/test_data.json\"\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df =  pd.read_json(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2151de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HLER\\AppData\\Local\\Temp\\ipykernel_24700\\2264422588.py:6: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the `langchain-neo4j package and should be used instead. To use it run `pip install -U `langchain-neo4j` and import as `from `langchain_neo4j import Neo4jGraph``.\n",
      "  graph = Neo4jGraph(\n"
     ]
    }
   ],
   "source": [
    "# Log-in and setup database connection\n",
    "url = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"password\"\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7362fca4",
   "metadata": {},
   "source": [
    "### Define helpful prompts and linkages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e38233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_types = {\n",
    "    \"document\": \"Represents a digital file stored in the system, such as a PDF, drawing, or report. Each document node stores metadata like name, path, size, imported date, and template flag.\",\n",
    "    \"user\": \"Represents the person or account who imported, created, or owns the document. Typically identified by username.\",\n",
    "    \"file_type\": \"Represents the document format, such as 'PDF', 'DOCX', or 'DWG'. Shared across multiple documents to avoid duplication.\",\n",
    "    \"status\": \"Represents the current or historical status of a document (e.g., draft, approved, archived). May also hold status codes or timestamps.\",\n",
    "    \"file_date\": \"Represents temporal information related to the document, such as the creation or modification date and time. Useful for time-based queries.\",\n",
    "    \"description\": \"Represents a semantic classification or content type of the document â€” for example 'PROCEDURE', 'MANUAL', 'DRAWING', 'SPECIFICATION'.\"\n",
    "}\n",
    "\n",
    "relation_types = {\n",
    "    \"IMPORTED_BY\": \"Indicates which user imported the document into the system.\",\n",
    "    \"HAS_FORMAT\": \"Links a document to its file format (PDF, DOCX, etc.).\",\n",
    "    \"HAS_STATUS\": \"Associates a document with its workflow or approval status.\",\n",
    "    \"HAS_FILETIME\": \"Links a document to its file date and time metadata.\",\n",
    "    \"IS_TYPE\": \"Classifies the document by description or semantic category (e.g., PROCEDURE, MANUAL).\"\n",
    "}\n",
    "\n",
    "entity_relationship_match = {\n",
    "    \"user\": \"IMPORTED_BY\",\n",
    "    \"file_type\": \"HAS_FORMAT\",\n",
    "    \"status\": \"HAS_STATUS\",\n",
    "    \"file_date\": \"HAS_FILETIME\",\n",
    "    \"description\": \"IS_TYPE\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15aa09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are an intelligent retrieval planner designed to extract **structured query intent** from a user's natural language question,\n",
    "so that it can be executed against a **Neo4j knowledge graph** of documents and their metadata.\n",
    "\n",
    "---\n",
    "\n",
    "### Graph Schema Overview\n",
    "\n",
    "Each document node (`Document`) is linked to several **entity types** representing its metadata and attributes:\n",
    "{json.dumps(entity_types, indent=4)}\n",
    "\n",
    "Each connection between a `Document` node and an entity uses one of the following **relationship types**:\n",
    "{json.dumps(relation_types, indent=4)}\n",
    "\n",
    "These relationships describe how documents connect to users, formats, statuses, and time of import.\n",
    "\n",
    "---\n",
    "\n",
    "### Your Role\n",
    "\n",
    "1. **Interpret the user's intent.**\n",
    "   - Understand what the user wants to *find* (e.g., a document, a status, a date, a user, etc.).\n",
    "   - Identify *which parts of the graph* (entity types) are relevant.\n",
    "\n",
    "2. **Extract query parameters.**\n",
    "   - Map each piece of meaningful information from the userâ€™s question to the **correct entity type** key.\n",
    "   - Include only information that exists as nodes or relationships in the graph schema.\n",
    "   - If the user asks about a *specific document*, include `\"Document\": \"<document_name>\"`.\n",
    "   - If they ask about *a property or relation* of that document (like status or date), include both the document and the requested entity type.\n",
    "\n",
    "3. **Focus on semantics, not surface keywords.**\n",
    "   - Recognize synonyms, natural expressions, and implied attributes.\n",
    "   - Example: â€œWho importedâ€¦â€ â†’ `User`\n",
    "   - Example: â€œWhen was it created?â€ â†’ `FileDate`\n",
    "   - Example: â€œWhatâ€™s its current state?â€ â†’ `Status`\n",
    "   - Example: â€œShow me all proceduresâ€ â†’ `Description: \"procedure\"`\n",
    "\n",
    "4. **Return a JSON object** with one key per relevant entity type and the corresponding value.\n",
    "   - Key names **must match exactly** one of the entity types above.\n",
    "   - If nothing in the question maps to known entity types, return an **empty JSON object**.\n",
    "\n",
    "---\n",
    "\n",
    "### Examples\n",
    "\n",
    "**User input:**\n",
    "> Find procedure PDF files imported by haaler on November 9th 2024 with status 0.\n",
    "\n",
    "**Expected output:**\n",
    "```json\n",
    "{{\n",
    "    \"Description\": \"Procedure\",\n",
    "    \"FileType\": \"PDF\",\n",
    "    \"User\": \"haaler\",\n",
    "    \"FileDate\": \"Wed Nov 9 2024\",\n",
    "    \"Status\": 0\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d94024",
   "metadata": {},
   "source": [
    "## Create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db17a079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Inserting document #1 (PROCEDURE)\n",
      "2. Inserting document #2 (REPORT)\n",
      "3. Inserting document #3 (Onshore Risk Assessment)\n",
      "4. Inserting document #4 (Jobcard)\n"
     ]
    }
   ],
   "source": [
    "# --- HELPER ---\n",
    "def clear_graph(tx):\n",
    "    tx.run(\"MATCH (n) DETACH DELETE n;\")\n",
    "\n",
    "def sanitize(text):\n",
    "    return str(text).replace('\"', '').replace(\"'\", \"\").replace('{','').replace('}', '')\n",
    "\n",
    "# Loop through each JSON object and add them to the DB\n",
    "i = 1\n",
    "for obj in data:\n",
    "    print(f\"{i}. Inserting document #{obj['uniqueid']} ({obj['Description']})\")\n",
    "    i += 1\n",
    "\n",
    "    # Cypher query with fixed schema (no dynamic labels or relationships)\n",
    "    query = \"\"\"\n",
    "    MERGE (d:Document {id: $id})\n",
    "    ON CREATE SET\n",
    "        d.name        = $name,\n",
    "        d.title       = $title,\n",
    "        d.path        = $path,\n",
    "        d.user        = $user,\n",
    "        d.description = $description,\n",
    "        d.format      = $file_format,\n",
    "        d.size        = $size_str,\n",
    "        d.imported    = $imported,\n",
    "        d.template    = $template\n",
    "\n",
    "    MERGE (u:User {name: $user})\n",
    "    MERGE (ff:FileType {name: $file_format})\n",
    "    MERGE (s:Status {code: $status_code})\n",
    "    MERGE (fd:FileDate {date_str: $file_date, time_str: $file_time})\n",
    "    MERGE (t:Description {type: $description})\n",
    "\n",
    "    MERGE (d)-[:IMPORTED_BY]->(u)\n",
    "    MERGE (d)-[:HAS_FORMAT]->(ff)\n",
    "    MERGE (d)-[hs:HAS_STATUS]->(s)\n",
    "      ON CREATE SET hs.at = $status_date\n",
    "    MERGE (d)-[:HAS_FILETIME]->(fd)\n",
    "    MERGE (d)-[:IS_TYPE]->(t)\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameters for this record\n",
    "    params = {\n",
    "        \"id\": obj[\"uniqueid\"],\n",
    "        \"name\": obj.get(\"filename\", \"\"),\n",
    "        \"title\": obj.get(\"orig.filename\", \"\"),\n",
    "        \"path\": obj.get(\"path\", \"\"),\n",
    "        \"user\": obj.get(\"User\", \"\"),\n",
    "        \"description\": obj.get(\"Description\", \"\"),\n",
    "        \"file_format\": obj.get(\"FileType\", \"\"),\n",
    "        \"size_str\": obj.get(\"FileSize\", \"\"),\n",
    "        \"imported\": obj.get(\"Imported\", \"\"),\n",
    "        \"template\": obj.get(\"Template\", 0),\n",
    "        \"status_code\": obj.get(\"Status\", 0),\n",
    "        \"status_date\": obj.get(\"StatusDate\", \"\"),\n",
    "        \"file_date\": obj.get(\"FileDate\", \"\"),\n",
    "        \"file_time\": obj.get(\"FileTime\", \"\")\n",
    "    }\n",
    "\n",
    "    # Run safely with parameters\n",
    "    graph.query(query, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad398bc1",
   "metadata": {},
   "source": [
    "## RAG: Embedding and vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af90431",
   "metadata": {},
   "source": [
    "#### Embedding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adc7b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Creating/Updating embedding index for 'Document' using properties: ['name', 'title', 'description', 'path', 'format']\n",
      "âœ… Successfully embedded 'Document' nodes into vector index 'documents'\n",
      "ðŸ”¹ Creating/Updating embedding index for 'User' using properties: ['name']\n",
      "âœ… Successfully embedded 'User' nodes into vector index 'user_index'\n",
      "ðŸ”¹ Creating/Updating embedding index for 'FileType' using properties: ['name']\n",
      "âœ… Successfully embedded 'FileType' nodes into vector index 'filetype_index'\n",
      "ðŸ”¹ Creating/Updating embedding index for 'Status' using properties: ['code']\n",
      "âœ… Successfully embedded 'Status' nodes into vector index 'status_index'\n",
      "ðŸ”¹ Creating/Updating embedding index for 'FileDate' using properties: ['date_str', 'time_str']\n",
      "âœ… Successfully embedded 'FileDate' nodes into vector index 'filedate_index'\n",
      "ðŸ”¹ Creating/Updating embedding index for 'Description' using properties: ['type']\n",
      "âœ… Successfully embedded 'Description' nodes into vector index 'description_index'\n"
     ]
    }
   ],
   "source": [
    "ollama_embedding_model = \"qwen3-embedding:0.6b\"\n",
    "def embed_neo4j_nodes(node_label, index_name=None, text_props=None, embedding_model=None):\n",
    "    \"\"\"\n",
    "    Create or update Neo4j vector indexes for nodes of a given label.\n",
    "\n",
    "    Args:\n",
    "        node_label (str): The Neo4j node label (e.g. \"Document\", \"User\", \"FileType\").\n",
    "        index_name (str, optional): Name of the vector index (defaults to the node_label).\n",
    "        text_props (list, optional): Properties to embed into the vector.\n",
    "        embedding_model (str, optional): Ollama embedding model (defaults to your global one).\n",
    "    \"\"\"\n",
    "\n",
    "    # Default embedding model if none is passed\n",
    "    if embedding_model is None:\n",
    "        embedding_model = \"embeddinggemma:300m\"\n",
    "\n",
    "    if index_name is None:\n",
    "        index_name = node_label.lower() + \"_index\"\n",
    "\n",
    "    # Default text properties per node type\n",
    "    if text_props is None:\n",
    "        match node_label:\n",
    "            case \"Document\":\n",
    "                text_props = [\"name\", \"title\", \"description\", \"path\", \"format\"]\n",
    "            case \"User\":\n",
    "                text_props = [\"name\"]\n",
    "            case \"FileType\":\n",
    "                text_props = [\"name\"]\n",
    "            case \"Status\":\n",
    "                text_props = [\"code\"]\n",
    "            case \"FileDate\":\n",
    "                text_props = [\"date_str\", \"time_str\"]\n",
    "            case \"Description\":\n",
    "                text_props = [\"type\"]\n",
    "            case _:\n",
    "                text_props = [\"name\"]  # fallback\n",
    "\n",
    "    print(f\"ðŸ”¹ Creating/Updating embedding index for '{node_label}' using properties: {text_props}\")\n",
    "\n",
    "    try:\n",
    "        vector_index = Neo4jVector.from_existing_graph(\n",
    "            OllamaEmbeddings(model=embedding_model),\n",
    "            url=url,\n",
    "            username=username,\n",
    "            password=password,\n",
    "            index_name=index_name,\n",
    "            node_label=node_label,\n",
    "            text_node_properties=text_props,\n",
    "            embedding_node_property=\"embedding\",\n",
    "        )\n",
    "        print(f\"âœ… Successfully embedded '{node_label}' nodes into vector index '{index_name}'\")\n",
    "        return vector_index\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed to embed '{node_label}': {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- 1ï¸âƒ£ Embed your main Document nodes ---\n",
    "embed_neo4j_nodes(\"Document\", index_name=\"documents\", embedding_model=ollama_embedding_model)\n",
    "\n",
    "# --- 2ï¸âƒ£ Embed all related entities (Users, FileTypes, etc.) ---\n",
    "related_labels = [\"User\", \"FileType\", \"Status\", \"FileDate\", \"Description\"]\n",
    "\n",
    "for label in related_labels:\n",
    "    embed_neo4j_nodes(label, embedding_model=ollama_embedding_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d901c3ec",
   "metadata": {},
   "source": [
    "#### Embedding the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "160e443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_client = OllamaEmbeddings(model=ollama_embedding_model)\n",
    "\n",
    "def create_embedding(text):\n",
    "    return embeddings_client.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82db65aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query(text, threshold=0.65):\n",
    "    query_data = json.loads(text)\n",
    "    embeddings_data = []\n",
    "    match_data = []\n",
    "    similarity_data = []\n",
    "\n",
    "    # Build WITH clause\n",
    "    for key in query_data:\n",
    "        if key.lower() != \"document\":\n",
    "            embeddings_data.append(f\"${key}Embedding AS {key}Embedding\")\n",
    "\n",
    "    query = \"WITH \" + \",\\n\".join(embeddings_data) + \"\\nMATCH (d:Document)\\n\"\n",
    "\n",
    "    # Dynamically build MATCH and WHERE clauses only for keys present\n",
    "    for key in query_data:\n",
    "        if key.lower() != \"document\":\n",
    "            relationship = entity_relationship_match.get(key.lower())\n",
    "            if relationship:\n",
    "                var_name = f\"{key}Var\"\n",
    "                match_data.append(f\"MATCH (d)-[:{relationship}]->({var_name}:{key})\")\n",
    "                similarity_data.append(\n",
    "                    f\"gds.similarity.cosine({var_name}.embedding, ${key}Embedding) > {threshold}\"\n",
    "                )\n",
    "\n",
    "    # Add matches only if they exist\n",
    "    if match_data:\n",
    "        query += \"\\n\".join(match_data) + \"\\n\"\n",
    "\n",
    "    # Add where clause safely\n",
    "    if similarity_data:\n",
    "        query += \"WHERE \" + \" AND \".join(similarity_data) + \"\\n\"\n",
    "\n",
    "    query += \"RETURN d\"\n",
    "    return query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "812c1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_graph(response):\n",
    "    embeddingsParams = {}\n",
    "    query = create_query(response)\n",
    "    query_data = json.loads(response)\n",
    "    for key, val in query_data.items():\n",
    "        embeddingsParams[f\"{key}Embedding\"] = create_embedding(val)\n",
    "    result = graph.query(query, params=embeddingsParams)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7cccce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_response = '''{\n",
    "    \"Description\": \"Procedure\",\n",
    "    \"FileType\": \"PDF\",\n",
    "    \"User\": \"haaler\",\n",
    "    \"FileDate\": \"Wed Nov  5 2025\",\n",
    "    \"Status\": \"0\"\n",
    "}'''\n",
    "\n",
    "result = query_graph(example_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c281c7f",
   "metadata": {},
   "source": [
    "#### Vector Search Result: Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7dbefc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found 1 matching document(s):\n",
      "\n",
      "ðŸ—Ž  45321-J-KA-0001 (1)\n",
      "   â”œ Title: Kasra Taheri.pdf\n",
      "   â”œ Type:  PDF\n",
      "   â”œ User:  haaler\n",
      "   â”” Imported: Wed Nov  5 13:29:07 2025 CET\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Result display ---\n",
    "if not result or len(result) == 0:\n",
    "    print(\"âš ï¸ No matching documents found.\\n\")\n",
    "else:\n",
    "    print(f\"âœ… Found {len(result)} matching document(s):\\n\")\n",
    "\n",
    "    for record in result:\n",
    "        # Each record has a key 'd' from \"RETURN d\"\n",
    "        doc = record.get(\"d\", {})\n",
    "\n",
    "        # Safely extract properties\n",
    "        doc_id = doc.get(\"id\", \"N/A\")\n",
    "        doc_name = doc.get(\"name\", \"Unnamed Document\")\n",
    "        doc_title = doc.get(\"title\", \"\")\n",
    "        doc_type = doc.get(\"format\", doc.get(\"type\", \"Unknown Format\"))\n",
    "        doc_user = doc.get(\"user\", \"Unknown User\")\n",
    "        doc_date = doc.get(\"imported\", \"\")\n",
    "\n",
    "        # Pretty print summary\n",
    "        print(f\"ðŸ—Ž  {doc_name} ({doc_id})\")\n",
    "        print(f\"   â”œ Title: {doc_title}\")\n",
    "        print(f\"   â”œ Type:  {doc_type}\")\n",
    "        print(f\"   â”œ User:  {doc_user}\")\n",
    "        print(f\"   â”” Imported: {doc_date}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2eb6a6",
   "metadata": {},
   "source": [
    "## GraphRAG: Graph Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf1beba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust relationships_threshold to return documents that share more or fewer connected entities\n",
    "def query_similar_documents(document_id, relationships_threshold=3):\n",
    "    similar_docs = []\n",
    "\n",
    "    # --- 1ï¸âƒ£ Documents with the same Description type (e.g., PROCEDURE, MANUAL, DRAWING) ---\n",
    "    query_same_description = \"\"\"\n",
    "        MATCH (d:Document {id: $document_id})-[:IS_TYPE]->(desc:Description)\n",
    "        MATCH (d)-->(entity)\n",
    "        WHERE NOT entity:Description\n",
    "        MATCH (n:Document)-[:IS_TYPE]->(desc)\n",
    "        MATCH (n)-->(commonEntity)\n",
    "        WHERE commonEntity = entity AND d.id <> n.id\n",
    "        RETURN DISTINCT n;\n",
    "    \"\"\"\n",
    "\n",
    "    result_description = graph.query(query_same_description, params={\"document_id\": int(document_id)})\n",
    "\n",
    "    # --- 2ï¸âƒ£ Documents sharing at least N other entities (e.g., same User, FileType, or Status) ---\n",
    "    query_common_entities = \"\"\"\n",
    "        MATCH (d:Document {id: $document_id})-->(entity),\n",
    "              (n:Document)-->(entity)\n",
    "        WHERE d.id <> n.id\n",
    "        WITH n, COUNT(DISTINCT entity) AS commonEntities\n",
    "        WHERE commonEntities >= $threshold\n",
    "        RETURN n;\n",
    "    \"\"\"\n",
    "\n",
    "    result_common_entities = graph.query(\n",
    "        query_common_entities,\n",
    "        params={\"document_id\": int(document_id), \"threshold\": relationships_threshold}\n",
    "    )\n",
    "\n",
    "    # --- 3ï¸âƒ£ Combine results and deduplicate ---\n",
    "    for r in result_description:\n",
    "        similar_docs.append({\n",
    "            \"id\": r['n'].get('id', 'N/A'),\n",
    "            \"name\": r['n'].get('name', 'Unnamed Document')\n",
    "        })\n",
    "\n",
    "    for r in result_common_entities:\n",
    "        result_id = r['n'].get('id', 'N/A')\n",
    "        if not any(item['id'] == result_id for item in similar_docs):\n",
    "            similar_docs.append({\n",
    "                \"id\": result_id,\n",
    "                \"name\": r['n'].get('name', 'Unnamed Document')\n",
    "            })\n",
    "\n",
    "    # --- 4ï¸âƒ£ Return results ---\n",
    "    return similar_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "60cbe2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Similar documents for document #1:\n",
      "\n",
      "   âš ï¸ No similar documents found.\n",
      "\n",
      "ðŸ“„ Similar documents for document #2:\n",
      "\n",
      "   â€¢ 83743-P-OR-0002 (ID: 3)\n",
      "\n",
      "\n",
      "ðŸ“„ Similar documents for document #3:\n",
      "\n",
      "   â€¢ 32352-F-RA-0003 (ID: 2)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_ids = [1, 2, 3]  # example IDs\n",
    "\n",
    "for document_id in document_ids:\n",
    "    print(f\"ðŸ“„ Similar documents for document #{document_id}:\\n\")\n",
    "    result = query_similar_documents(document_id)\n",
    "    \n",
    "    if not result:\n",
    "        print(\"   âš ï¸ No similar documents found.\\n\")\n",
    "        continue\n",
    "\n",
    "    for r in result:\n",
    "        print(f\"   â€¢ {r['name']} (ID: {r['id']})\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1d5c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(params):\n",
    "    matches = []\n",
    "    # Query the database using your embedding-based GraphRAG query\n",
    "    result = query_graph(params)\n",
    "\n",
    "    for r in result:\n",
    "        doc = r.get(\"d\", {})  # Neo4j returns the variable alias 'd' (from RETURN d)\n",
    "        doc_id = doc.get(\"id\", \"N/A\")\n",
    "        doc_name = doc.get(\"name\", \"Unnamed Document\")\n",
    "\n",
    "        matches.append({\n",
    "            \"id\": doc_id,\n",
    "            \"name\": doc_name\n",
    "        })\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bbfc94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_search(prompt, threshold=0.60):\n",
    "    \"\"\"\n",
    "    Perform semantic similarity search over Document nodes based on the given text prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The natural-language search text (e.g., \"procedure PDF imported by haaler\").\n",
    "        threshold (float): Minimum cosine similarity threshold (0â€“1).\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: Matching documents with their IDs and names.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "\n",
    "    # Convert query text into an embedding using your Ollama embedding model\n",
    "    embedding = create_embedding(prompt)\n",
    "\n",
    "    # Cypher query: compare embedding similarity to all Document nodes\n",
    "    query = '''\n",
    "        WITH $embedding AS inputEmbedding\n",
    "        MATCH (d:Document)\n",
    "        WHERE d.embedding IS NOT NULL\n",
    "          AND gds.similarity.cosine(inputEmbedding, d.embedding) > $threshold\n",
    "        RETURN d\n",
    "        ORDER BY gds.similarity.cosine(inputEmbedding, d.embedding) DESC\n",
    "        LIMIT 10\n",
    "    '''\n",
    "\n",
    "    result = graph.query(query, params={'embedding': embedding, 'threshold': threshold})\n",
    "\n",
    "    for r in result:\n",
    "        d = r.get('d', {})\n",
    "        doc_id = d.get('id', 'N/A')\n",
    "        doc_name = d.get('name', 'Unnamed Document')\n",
    "\n",
    "        matches.append({\n",
    "            \"id\": doc_id,\n",
    "            \"name\": doc_name\n",
    "        })\n",
    "\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e216a93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'name': '45321-J-KA-0001'}]\n"
     ]
    }
   ],
   "source": [
    "prompt_similarity = \"Find documents about procedures imported by haaler\"\n",
    "print(similarity_search(prompt_similarity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dat300",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
