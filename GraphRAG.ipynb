{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba03d9d",
   "metadata": {},
   "source": [
    "### Prepare the code and setup database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9a5d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "#from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_neo4j import Neo4jVector\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from utils.pdf_utils import extract_pdf_text_by_page, chunk_pages\n",
    "from langchain_core.messages import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f980d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and read data\n",
    "data_path = \"data_json/test_data.json\"\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df =  pd.read_json(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f94db02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-in and setup database connection\n",
    "url = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"password\"\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b157c409",
   "metadata": {},
   "source": [
    "### Define helpful prompts and linkages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e8976b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_types = {\n",
    "    \"document\": \"Represents a digital file stored in the system, such as a PDF, drawing, or report. Each document node stores metadata like name, path, size, imported date, and template flag.\",\n",
    "    \"user\": \"Represents the person or account who imported, created, or owns the document. Typically identified by username.\",\n",
    "    \"file_type\": \"Represents the document format, such as 'PDF', 'DOCX', or 'DWG'. Shared across multiple documents to avoid duplication.\",\n",
    "    \"status\": \"Represents the current or historical status of a document (e.g., draft, approved, archived). May also hold status codes or timestamps.\",\n",
    "    \"file_date\": \"Represents temporal information related to the document, such as the creation or modification date and time. Useful for time-based queries.\",\n",
    "    \"description\": \"Represents a semantic classification or content type of the document ‚Äî for example 'PROCEDURE', 'MANUAL', 'DRAWING', 'SPECIFICATION'.\"\n",
    "}\n",
    "\n",
    "relation_types = {\n",
    "    \"IMPORTED_BY\": \"Indicates which user imported the document into the system.\",\n",
    "    \"HAS_FORMAT\": \"Links a document to its file format (PDF, DOCX, etc.).\",\n",
    "    \"HAS_STATUS\": \"Associates a document with its workflow or approval status.\",\n",
    "    \"HAS_FILETIME\": \"Links a document to its file date and time metadata.\",\n",
    "    \"IS_TYPE\": \"Classifies the document by description or semantic category (e.g., PROCEDURE, MANUAL).\"\n",
    "}\n",
    "\n",
    "entity_relationship_match = {\n",
    "    \"user\": \"IMPORTED_BY\",\n",
    "    \"file_type\": \"HAS_FORMAT\",\n",
    "    \"status\": \"HAS_STATUS\",\n",
    "    \"file_date\": \"HAS_FILETIME\",\n",
    "    \"description\": \"IS_TYPE\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6948be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are an intelligent assistant that converts natural language questions into structured JSON\n",
    "queries for a Neo4j document graph.\n",
    "\n",
    "The graph stores these entity types:\n",
    "{json.dumps(entity_types, indent=2)}\n",
    "\n",
    "Relationships between them:\n",
    "{json.dumps(relation_types, indent=2)}\n",
    "\n",
    "Each user query may reference one or more of these entities (e.g., User, Description, FileType, Status, FileDate).\n",
    "Your goal is to extract as many of them as possible and return a JSON object with their corresponding values.\n",
    "\n",
    "Follow these rules:\n",
    "1Ô∏è‚É£ Always output valid JSON.\n",
    "2Ô∏è‚É£ Include keys only from the entity_types list.\n",
    "3Ô∏è‚É£ If the query references a document or file, include `\"Document\": \"<name>\"`.\n",
    "4Ô∏è‚É£ If unsure, infer the most likely match (e.g., \"procedure\" ‚Üí `\"Description\": \"Procedure\"`, \"PDF\" ‚Üí `\"FileType\": \"PDF\"`).\n",
    "5Ô∏è‚É£ If no information can be extracted, return an empty JSON.\n",
    "\n",
    "Examples:\n",
    "\n",
    "User: \"Find all procedures imported by haaler related to PDF files.\"\n",
    "Output:\n",
    "{{\n",
    "  \"Description\": \"Procedure\",\n",
    "  \"FileType\": \"PDF\",\n",
    "  \"User\": \"haaler\"\n",
    "}}\n",
    "\n",
    "User: \"When was the document Kasra Taheri created?\"\n",
    "Output:\n",
    "{{\n",
    "  \"Document\": \"Kasra Taheri\",\n",
    "  \"FileDate\": \"\"\n",
    "}}\n",
    "\n",
    "User: \"What is the current status on the document Dick Ackerman?\"\n",
    "Output:\n",
    "{{\n",
    "  \"Document\": \"Dick Ackerman\",\n",
    "  \"Status\": \"\"\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c0f6e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_REASONING_PROMPT = \"\"\"\n",
    "You are an assistant that answers questions about a knowledge graph of documents.\n",
    "The graph contains entities like Document, User, FileType, Description, and Status.\n",
    "You will be given:\n",
    "1. A structured query (key‚Äìvalue pairs)\n",
    "2. A subgraph context (retrieved from the graph)\n",
    "Use them to answer concisely and factually.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3dc131",
   "metadata": {},
   "source": [
    "### Create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7d00855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Inserting document #1 (PROCEDURE)\n",
      "2. Inserting document #2 (REPORT)\n",
      "3. Inserting document #3 (Onshore Risk Assessment)\n",
      "4. Inserting document #4 (Jobcard)\n"
     ]
    }
   ],
   "source": [
    "# --- HELPER ---\n",
    "def sanitize(text):\n",
    "    return str(text).replace('\"', '').replace(\"'\", \"\").replace('{','').replace('}', '')\n",
    "\n",
    "# Loop through each JSON object and add them to the DB\n",
    "i = 1\n",
    "for obj in data:\n",
    "    print(f\"{i}. Inserting document #{obj['uniqueid']} ({obj['Description']})\")\n",
    "    i += 1\n",
    "\n",
    "    # Cypher query with fixed schema (no dynamic labels or relationships)\n",
    "    query = \"\"\"\n",
    "    MERGE (d:Document {id: $id})\n",
    "    ON CREATE SET\n",
    "        d.name        = $name,\n",
    "        d.title       = $title,\n",
    "        d.path        = $path,\n",
    "        d.user        = $user,\n",
    "        d.description = $description,\n",
    "        d.format      = $file_format,\n",
    "        d.size        = $size_str,\n",
    "        d.imported    = $imported,\n",
    "        d.template    = $template\n",
    "\n",
    "    MERGE (u:User {name: $user})\n",
    "    MERGE (ff:FileType {name: $file_format})\n",
    "    MERGE (s:Status {code: $status_code})\n",
    "    MERGE (fd:FileDate {date_str: $file_date, time_str: $file_time})\n",
    "    MERGE (t:Description {type: $description})\n",
    "\n",
    "    MERGE (d)-[:IMPORTED_BY]->(u)\n",
    "    MERGE (d)-[:HAS_FORMAT]->(ff)\n",
    "    MERGE (d)-[hs:HAS_STATUS]->(s)\n",
    "      ON CREATE SET hs.at = $status_date\n",
    "    MERGE (d)-[:HAS_FILETIME]->(fd)\n",
    "    MERGE (d)-[:IS_TYPE]->(t)\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameters for this record\n",
    "    params = {\n",
    "        \"id\": obj[\"uniqueid\"],\n",
    "        \"name\": obj.get(\"filename\", \"\"),\n",
    "        \"title\": obj.get(\"orig.filename\", \"\"),\n",
    "        \"path\": obj.get(\"path\", \"\"),\n",
    "        \"user\": obj.get(\"User\", \"\"),\n",
    "        \"description\": obj.get(\"Description\", \"\"),\n",
    "        \"file_format\": obj.get(\"FileType\", \"\"),\n",
    "        \"size_str\": obj.get(\"FileSize\", \"\"),\n",
    "        \"imported\": obj.get(\"Imported\", \"\"),\n",
    "        \"template\": obj.get(\"Template\", 0),\n",
    "        \"status_code\": obj.get(\"Status\", 0),\n",
    "        \"status_date\": obj.get(\"StatusDate\", \"\"),\n",
    "        \"file_date\": obj.get(\"FileDate\", \"\"),\n",
    "        \"file_time\": obj.get(\"FileTime\", \"\")\n",
    "    }\n",
    "\n",
    "    # Run safely with parameters\n",
    "    graph.query(query, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6d293",
   "metadata": {},
   "source": [
    "### Embed the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e14f6006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Creating/Updating embedding index for 'Document' using properties: ['name', 'title', 'description', 'path', 'format', 'user']\n",
      "‚úÖ Successfully embedded 'Document' nodes into vector index 'documents'\n",
      "üîπ Creating/Updating embedding index for 'User' using properties: ['name']\n",
      "‚úÖ Successfully embedded 'User' nodes into vector index 'user_index'\n",
      "üîπ Creating/Updating embedding index for 'FileType' using properties: ['name']\n",
      "‚úÖ Successfully embedded 'FileType' nodes into vector index 'filetype_index'\n",
      "üîπ Creating/Updating embedding index for 'Status' using properties: ['code']\n",
      "‚úÖ Successfully embedded 'Status' nodes into vector index 'status_index'\n",
      "üîπ Creating/Updating embedding index for 'FileDate' using properties: ['date_str', 'time_str']\n",
      "‚úÖ Successfully embedded 'FileDate' nodes into vector index 'filedate_index'\n",
      "üîπ Creating/Updating embedding index for 'Description' using properties: ['type']\n",
      "‚úÖ Successfully embedded 'Description' nodes into vector index 'description_index'\n"
     ]
    }
   ],
   "source": [
    "ollama_embedding_model = \"qwen3-embedding:0.6b\"\n",
    "def embed_neo4j_nodes(node_label, index_name=None, text_props=None, embedding_model=None):\n",
    "    \"\"\"\n",
    "    Create or update Neo4j vector indexes for nodes of a given label.\n",
    "\n",
    "    Args:\n",
    "        node_label (str): The Neo4j node label (e.g. \"Document\", \"User\", \"FileType\").\n",
    "        index_name (str, optional): Name of the vector index (defaults to the node_label).\n",
    "        text_props (list, optional): Properties to embed into the vector.\n",
    "        embedding_model (str, optional): Ollama embedding model (defaults to your global one).\n",
    "    \"\"\"\n",
    "\n",
    "    if index_name is None:\n",
    "        index_name = node_label.lower() + \"_index\"\n",
    "\n",
    "    # Default text properties per node type\n",
    "    if text_props is None:\n",
    "        match node_label:\n",
    "            case \"Document\":\n",
    "                text_props = [\"name\", \"title\", \"description\", \"path\", \"format\", \"user\"]\n",
    "            case \"User\":\n",
    "                text_props = [\"name\"]\n",
    "            case \"FileType\":\n",
    "                text_props = [\"name\"]\n",
    "            case \"Status\":\n",
    "                text_props = [\"code\"]\n",
    "            case \"FileDate\":\n",
    "                text_props = [\"date_str\", \"time_str\"]\n",
    "            case \"Description\":\n",
    "                text_props = [\"type\"]\n",
    "            case _:\n",
    "                text_props = [\"name\"]  # fallback\n",
    "\n",
    "    print(f\"üîπ Creating/Updating embedding index for '{node_label}' using properties: {text_props}\")\n",
    "\n",
    "    try:\n",
    "        vector_index = Neo4jVector.from_existing_graph(\n",
    "            OllamaEmbeddings(model=embedding_model),\n",
    "            url=url,\n",
    "            username=username,\n",
    "            password=password,\n",
    "            index_name=index_name,\n",
    "            node_label=node_label,\n",
    "            text_node_properties=text_props,\n",
    "            embedding_node_property=\"embedding\",\n",
    "        )\n",
    "        print(f\"‚úÖ Successfully embedded '{node_label}' nodes into vector index '{index_name}'\")\n",
    "        return vector_index\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to embed '{node_label}': {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- 1Ô∏è‚É£ Embed your main Document nodes ---\n",
    "embed_neo4j_nodes(\"Document\", index_name=\"documents\", embedding_model=ollama_embedding_model)\n",
    "\n",
    "# --- 2Ô∏è‚É£ Embed all related entities (Users, FileTypes, etc.) ---\n",
    "related_labels = [\"User\", \"FileType\", \"Status\", \"FileDate\", \"Description\"]\n",
    "\n",
    "for label in related_labels:\n",
    "    embed_neo4j_nodes(label, embedding_model=ollama_embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152ad616",
   "metadata": {},
   "source": [
    "### An LLM processes the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef344a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model = \"gemma3:4b\"\n",
    "def define_query(prompt, model=ollama_model):\n",
    "    llm = ChatOllama(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        format=\"json\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=prompt),\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af10a0cc",
   "metadata": {},
   "source": [
    "#### Embed the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6362ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_client = OllamaEmbeddings(model=ollama_embedding_model)\n",
    "\n",
    "def create_embedding(text):\n",
    "    return embeddings_client.embed_query(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65975284",
   "metadata": {},
   "source": [
    "### Vector / semantic retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "80a9c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_search(prompt, threshold, structured_query=None):\n",
    "    \"\"\"\n",
    "    Hybrid semantic + symbolic search over Document nodes.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    embedding = create_embedding(prompt)\n",
    "\n",
    "    query = '''\n",
    "        WITH $embedding AS inputEmbedding\n",
    "        MATCH (d:Document)\n",
    "        WHERE d.embedding IS NOT NULL\n",
    "          AND gds.similarity.cosine(inputEmbedding, d.embedding) > $threshold\n",
    "          AND ($user IS NULL OR toLower(d.user) = toLower($user))\n",
    "          AND ($fileType IS NULL OR toLower(d.format) = toLower($fileType))\n",
    "          AND ($description IS NULL OR toLower(d.description) CONTAINS toLower($description))\n",
    "        RETURN d, gds.similarity.cosine(inputEmbedding, d.embedding) AS sim\n",
    "        ORDER BY sim DESC\n",
    "        LIMIT 10\n",
    "    '''\n",
    "\n",
    "    params = {\n",
    "        'embedding': embedding,\n",
    "        'threshold': threshold,\n",
    "        'user': structured_query.get('User') if structured_query else None,\n",
    "        'fileType': structured_query.get('FileType') if structured_query else None,\n",
    "        'description': structured_query.get('Description') if structured_query else None\n",
    "    }\n",
    "\n",
    "    result = graph.query(query, params=params)\n",
    "    for r in result:\n",
    "        d = r.get('d', {})\n",
    "        matches.append({\n",
    "            \"id\": d.get('id'),\n",
    "            \"name\": d.get('name'),\n",
    "            \"similarity\": r.get('sim')\n",
    "        })\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45c2f7",
   "metadata": {},
   "source": [
    "### Graph-based retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27ac96b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_document_context(document_id, relationships_threshold):\n",
    "    \"\"\"\n",
    "    Fetches the connected entities around a single Document node.\n",
    "    Used for context enrichment in Mode A (no 'similar docs' expansion).\n",
    "\n",
    "    Returns:\n",
    "        dict: structured metadata for the given document.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    MATCH (d:Document {{id: $document_id}})\n",
    "    OPTIONAL MATCH path=(d)-[*1..{relationships_threshold}]-(n)\n",
    "    WITH d, collect(DISTINCT n) AS neighbors\n",
    "    OPTIONAL MATCH (d)-[:IMPORTED_BY]->(u:User)\n",
    "    OPTIONAL MATCH (d)-[:HAS_FORMAT]->(ft:FileType)\n",
    "    OPTIONAL MATCH (d)-[:HAS_STATUS]->(s:Status)\n",
    "    OPTIONAL MATCH (d)-[:HAS_FILETIME]->(fd:FileDate)\n",
    "    OPTIONAL MATCH (d)-[:IS_TYPE]->(desc:Description)\n",
    "    RETURN d,\n",
    "            u.name AS user,\n",
    "            ft.name AS file_type,\n",
    "            s.code AS status,\n",
    "            fd.date_str AS file_date,\n",
    "            desc.type AS description,\n",
    "            [n IN neighbors | labels(n)] AS neighbor_types\n",
    "    \"\"\"\n",
    "\n",
    "    result = graph.query(query, params={\"document_id\": int(document_id)})\n",
    "    if not result:\n",
    "        return None\n",
    "\n",
    "    r = result[0]\n",
    "    d = r.get(\"d\", {})\n",
    "    return {\n",
    "        \"id\": d.get(\"id\", \"N/A\"),\n",
    "        \"name\": d.get(\"name\", \"Unnamed Document\"),\n",
    "        \"title\": d.get(\"title\", \"\"),\n",
    "        \"description\": r.get(\"description\"),\n",
    "        \"file_type\": r.get(\"file_type\"),\n",
    "        \"user\": r.get(\"user\"),\n",
    "        \"status\": r.get(\"status\"),\n",
    "        \"file_date\": r.get(\"file_date\"),\n",
    "        \"imported\": d.get(\"imported\", \"\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b0a144",
   "metadata": {},
   "source": [
    "### Both approaches fused into one pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4d4e0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphrag_retrieve(prompt, threshold, relationships_threshold):\n",
    "    \"\"\"\n",
    "    Hybrid GraphRAG retriever combining:\n",
    "      1Ô∏è‚É£ LLM-guided query parsing\n",
    "      2Ô∏è‚É£ Semantic vector retrieval\n",
    "      3Ô∏è‚É£ Graph-based context expansion\n",
    "      4Ô∏è‚É£ LLM reasoning over the retrieved subgraph\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\nüîç Processing query: '{prompt}'\")\n",
    "\n",
    "    # --- 1Ô∏è‚É£ Step 1: Let the LLM interpret the user prompt ---\n",
    "    try:\n",
    "        structured_query = json.loads(define_query(prompt))\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Failed to parse structured query:\", e)\n",
    "        structured_query = {}\n",
    "\n",
    "    print(f\"üß© Structured query interpretation:\\n{structured_query}\\n\")\n",
    "\n",
    "    # --- 2Ô∏è‚É£ Step 2: Perform semantic similarity search over documents ---\n",
    "    query_terms = \" \".join(str(v) for v in structured_query.values() if v)\n",
    "    search_text = query_terms if query_terms else prompt\n",
    "    semantic_results = similarity_search(search_text, threshold, structured_query)\n",
    "\n",
    "    print(f\"üß† Found {len(semantic_results)} semantically similar document(s).\\n\")\n",
    "\n",
    "    if not semantic_results:\n",
    "        return \"‚ö†Ô∏è No semantically relevant documents found.\"\n",
    "\n",
    "    # --- 3Ô∏è‚É£ Step 3: Graph-based expansion ‚Äî get connected documents/entities ---\n",
    "    context_data = []\n",
    "    for doc in semantic_results:\n",
    "        doc_id = doc[\"id\"]\n",
    "        metadata = query_document_context(doc_id, relationships_threshold)\n",
    "        if metadata:\n",
    "            context_data.append(metadata)\n",
    "\n",
    "    print(f\"üß© Enriched {len(context_data)} document(s) with graph metadata.\\n\")\n",
    "\n",
    "\n",
    "    # --- 4Ô∏è‚É£ Step 4: Build a readable context summary for the LLM ---\n",
    "    context_summary = \"\\n\".join(\n",
    "        f\"‚Ä¢ {c['name']} (ID: {c['id']})\\n\"\n",
    "        f\"  Type: {c['description']}\\n\"\n",
    "        f\"  Format: {c['file_type']}\\n\"\n",
    "        f\"  User: {c['user']}\\n\"\n",
    "        f\"  Status: {c['status']}\\n\"\n",
    "        f\"  File Date: {c['file_date']}\\n\"\n",
    "        for c in context_data\n",
    "    )\n",
    "\n",
    "    print(f\"IDs from semantic search: {[d['id'] for d in semantic_results]}\")\n",
    "    print(f\"IDs enriched with metadata: {[c['id'] for c in context_data]}\")\n",
    "\n",
    "    # --- 5Ô∏è‚É£ Step 5: Ask the LLM again with the combined context ---\n",
    "    llm = ChatOllama(model=ollama_model, temperature=0)\n",
    "    messages = [\n",
    "        SystemMessage(content=SYSTEM_REASONING_PROMPT),\n",
    "        HumanMessage(content=f\"User question: {prompt}\\n\\nStructured query:\\n{json.dumps(structured_query, indent=2)}\\n\\nContext:\\n{context_summary}\\n\\nAnswer the question using this information only.\")\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    print(\"\\nüí¨ LLM Response:\\n\")\n",
    "    print(response.content)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc566bc",
   "metadata": {},
   "source": [
    "### Define user query and execute GraphRAG program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a567b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Processing query: 'Find all documents imported by dkar.'\n",
      "üß© Structured query interpretation:\n",
      "{'User': 'dkar'}\n",
      "\n",
      "üß† Found 1 semantically similar document(s).\n",
      "\n",
      "üß© Enriched 1 document(s) with graph metadata.\n",
      "\n",
      "IDs from semantic search: [2]\n",
      "IDs enriched with metadata: [2]\n",
      "\n",
      "üí¨ LLM Response:\n",
      "\n",
      "32352-F-RA-0003 is a document imported by dkar.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Find all documents imported by dkar.\"\n",
    "response = graphrag_retrieve(user_prompt, threshold=0.5, relationships_threshold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0a825",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Which information have we instructed the LLM to give about the document it finds? Because there are more nodes connected to the document other than it gives out. Hence why i am asking if it can find the description - or \"type\" field on the description node which now has the embedding as its name.\n",
    "- Only get 1 answer for \"Find all documents imported by dkar\", the answer is two. Implement weights?\n",
    "- Query in semantic search might be too specific. Specifically looking for user, description and filetype\n",
    "- Fix graph search to be an additional search through the nodes instead of just retrieving the nodes connected to the nodes the vector search found"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dat300",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
